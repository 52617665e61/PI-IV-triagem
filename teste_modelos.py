import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import joblib

# 1. Carregando os dados
df = pd.read_excel(r'C:\Users\USER\Desktop\dataser_PI-IV\12888_2022_4048_MOESM3_ESM.xlsx', header=1)

tr_cols = [f"tr{i}" for i in range(1, 44)]
X = df[tr_cols]
y = df["group"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 2. Definindo o espa칞o de busca para hiperpar칙metros
param_grid = {
    'n_estimators': [100, 200, 300],       # n칰mero de 치rvores
    'learning_rate': [0.01, 0.1, 0.2],     # taxa de aprendizado
    'max_depth': [3, 4, 5],                # profundidade m치xima
    'min_samples_split': [2, 5],           # m칤nimo para dividir um n칩
    'min_samples_leaf': [1, 2, 4],         # m칤nimo em uma folha
    'subsample': [0.8, 1.0]                # propor칞칚o de amostras para cada 치rvore
}

# 3. Configurando GridSearchCV
grid_search = GridSearchCV(
    estimator=GradientBoostingClassifier(random_state=42),
    param_grid=param_grid,
    cv=5,
    scoring='f1',  # f1-score para equilibrar precis칚o e recall
    verbose=2,
    n_jobs=-1
)

# 4. Treinando o modelo com busca de hiperpar칙metros
grid_search.fit(X_train, y_train)

# 5. Resultados
best_model = grid_search.best_estimator_
print("Melhores hiperpar칙metros:", grid_search.best_params_)

y_pred = best_model.predict(X_test)
print("游늵 Acur치cia:", accuracy_score(y_test, y_pred))
print("\n游늶 Classification Report:\n", classification_report(y_test, y_pred))
print("\n游빔 Matriz de Confus칚o:\n", confusion_matrix(y_test, y_pred))

# 6. Salvar modelo
joblib.dump(best_model, 'modelo_gradientboosting_otimizado.pkl')
